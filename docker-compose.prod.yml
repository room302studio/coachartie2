version: '3.8'

services:
  # Redis - Message queue and cache
  redis:
    image: redis:7-alpine
    container_name: coachartie-redis-prod
    command: >
      redis-server
      --port 47320
      --appendonly yes
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --appendfsync everysec
    ports:
      - "0.0.0.0:47320:47320"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-p", "47320", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 128M
    restart: unless-stopped
    networks:
      - coachartie-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # Capabilities - Core AI processing and capability orchestration
  capabilities:
    build:
      context: .
      dockerfile: ./packages/capabilities/Dockerfile
    container_name: coachartie-capabilities-prod
    user: "1000:1000"
    ports:
      - "0.0.0.0:47324:47324"
    env_file:
      - .env.production
    environment:
      - NODE_ENV=production
      - DATABASE_PATH=/app/data/coachartie.db
      - CAPABILITIES_PORT=47324
      - REDIS_HOST=redis
      - REDIS_PORT=47320
      - LOG_LEVEL=info
      - CONSOLE_LOG_LEVEL=info
      - SERVICE_NAME=capabilities
      - LOGS_DIR=/app/logs
      - SANDBOX_CONTAINER_NAME=coachartie-sandbox-prod
    volumes:
      - ./data:/app/data:rw
      - ./logs:/app/logs:rw
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:47324/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
    restart: unless-stopped
    networks:
      - coachartie-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # Discord - Discord bot integration
  discord:
    build:
      context: .
      dockerfile: ./packages/discord/Dockerfile
    container_name: coachartie-discord-prod
    user: "1000:1000"
    ports:
      - "0.0.0.0:47319:47319"
      - "0.0.0.0:47321:47321"
    env_file:
      - .env.production
    environment:
      - NODE_ENV=production
      - CAPABILITIES_URL=http://capabilities:47324
      - REDIS_HOST=redis
      - REDIS_PORT=47320
      - DISCORD_PORT=47321
      - DATABASE_PATH=/app/data/coachartie.db
      - LOG_LEVEL=info
      - CONSOLE_LOG_LEVEL=warn
      - SERVICE_NAME=discord
      - LOGS_DIR=/app/logs
      - DISCORD_STATUS_FILE=/app/data/discord-status.json
      - DISCORD_METRICS_FILE=/app/data/discord-metrics.json
      - DISCORD_EVENTS_FILE=/app/data/discord-events.json
      - INSTANCE_NAME=vps-prod
    volumes:
      - ./data:/app/data:rw
      - ./logs:/app/logs:rw
    depends_on:
      redis:
        condition: service_healthy
      capabilities:
        condition: service_healthy
    healthcheck:
      test: test -f /app/data/discord-status.json && grep -q '"ready":true' /app/data/discord-status.json || exit 1
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
    restart: unless-stopped
    networks:
      - coachartie-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # SMS - Twilio SMS integration
  sms:
    build:
      context: .
      dockerfile: ./packages/sms/Dockerfile
    container_name: coachartie-sms-prod
    user: "1000:1000"
    ports:
      - "0.0.0.0:47326:47326"
    env_file:
      - .env.production
    environment:
      - NODE_ENV=production
      - CAPABILITIES_URL=http://capabilities:47324
      - REDIS_HOST=redis
      - REDIS_PORT=47320
      - SMS_PORT=47326
      - LOG_LEVEL=info
      - CONSOLE_LOG_LEVEL=warn
      - SERVICE_NAME=sms
      - LOGS_DIR=/app/logs
    volumes:
      - ./logs:/app/logs:rw
    depends_on:
      redis:
        condition: service_healthy
      capabilities:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:47326/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 128M
    restart: unless-stopped
    networks:
      - coachartie-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # Brain - Web UI and monitoring dashboard
  brain:
    build:
      context: .
      dockerfile: ./packages/brain/Dockerfile
    container_name: coachartie-brain-prod
    user: "1000:1000"
    ports:
      - "0.0.0.0:47325:47325"
    env_file:
      - .env.production
    environment:
      - NODE_ENV=production
      - BRAIN_PORT=47325
      - CAPABILITIES_URL=http://capabilities:47324
      - API_BASE_URL=http://localhost:47324
      - REDIS_HOST=redis
      - REDIS_PORT=47320
      - DATABASE_PATH=/app/data/coachartie.db
      - LOG_LEVEL=info
      - CONSOLE_LOG_LEVEL=warn
      - SERVICE_NAME=brain
      - LOGS_DIR=/app/logs
      - HOST=0.0.0.0
      - PORT=47325
    volumes:
      - ./data:/app/data:rw
      - ./logs:/app/logs:rw
    depends_on:
      redis:
        condition: service_healthy
      capabilities:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:47325/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
    restart: unless-stopped
    networks:
      - coachartie-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # Sandbox - Isolated shell environment with tmux for Artie's CLI operations
  sandbox:
    image: debian:bookworm-slim
    container_name: coachartie-sandbox-prod
    hostname: artie-laptop
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M  # Increased from 128M for better performance
    # Limit /tmp to prevent disk exhaustion
    tmpfs:
      - /tmp:size=512M

    volumes:
      - sandbox-workspace:/workspace
      - sandbox-home:/root
    env_file:
      - .env.production
    environment:
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - HOME=/root
    command:
      - /bin/bash
      - -c
      - |
        # Install tools
        rm -rf /var/cache/apt/archives/* &&
        apt-get clean &&
        apt-get update -qq &&
        apt-get install -y -qq --fix-missing curl wget git jq python3 sqlite3 tmux procps &&
        curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg -o /usr/share/keyrings/githubcli-archive-keyring.gpg &&
        chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg &&
        echo "deb [arch=$$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" > /etc/apt/sources.list.d/github-cli.list &&
        apt-get update -qq &&
        apt-get install -y -qq --fix-missing gh &&

        if [ -n "$$GITHUB_TOKEN" ]; then
          echo 'âœ… GitHub CLI ready (using GITHUB_TOKEN)';
        else
          echo 'âš ï¸  GITHUB_TOKEN not set - gh CLI will have limited access';
        fi &&
        echo 'â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•' &&
        echo 'ğŸ–¥ï¸  Artie Laptop Ready (Production)' &&
        echo 'â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•' &&
        echo 'User: root (trusted chaos agent)' &&
        echo 'Tools: git, gh, jq, curl, python3, sqlite3, tmux' &&
        echo 'Workspace: /workspace' &&
        echo 'Tmux session: artie-main' &&
        echo 'Limits: 512M RAM, 1 CPU, 100 PIDs, 24h timeout' &&
        echo 'â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•' &&

        # Start tmux and keep running
        tmux new-session -d -s artie-main -c /workspace &&
        echo 'âœ… Tmux session artie-main started' &&

        # Kill container after 24 hours (prevents zombie containers)
        (sleep 86400 && echo "â° 24h timeout reached, shutting down..." && kill 1) &

        # Keep container running
        exec sleep infinity
    # Enhanced healthcheck - monitors system health + 24h timeout
    healthcheck:
      test: |
        # Check critical tools exist
        which gh tmux python3 git || exit 1

        # Check tmux session is alive
        tmux has-session -t artie-main || exit 1

        # Check uptime < 24h (auto-restart after)
        UPTIME=$$(awk '{print int($$1)}' /proc/uptime)
        [ $$UPTIME -lt 86400 ] || exit 1

        # Check process count (fork bomb detection)
        PROCS=$$(ps aux | wc -l)
        [ $$PROCS -lt 90 ] || exit 1

        # Check memory usage < 90%
        MEM_PERCENT=$$(free | grep Mem | awk '{print int($$3/$$2 * 100)}')
        [ $$MEM_PERCENT -lt 90 ] || exit 1
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - coachartie-prod
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

volumes:
  redis-data:
    driver: local
  sandbox-workspace:
    driver: local
  sandbox-home:
    driver: local

networks:
  coachartie-prod:
    driver: bridge
